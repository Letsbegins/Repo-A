{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e59813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "class DataFrameSpectralProcessor:\n",
    "    def __init__(self, dataframe=None):\n",
    "        \"\"\"\n",
    "        Initialize processor with optional 2D DataFrame\n",
    "        Args:\n",
    "            dataframe: 2D pandas DataFrame representing spectral/image data\n",
    "        \"\"\"\n",
    "        self.original_df = dataframe\n",
    "        self.current_df = None\n",
    "        self.data_blocks = {}\n",
    "        self.processed_spectra = {}\n",
    "        self.rotation_angle = 0\n",
    "        \n",
    "    def load_dataframe(self, dataframe):\n",
    "        \"\"\"Load 2D DataFrame\"\"\"\n",
    "        if not isinstance(dataframe, pd.DataFrame):\n",
    "            raise ValueError(\"Input must be a pandas DataFrame\")\n",
    "        \n",
    "        self.original_df = dataframe.copy()\n",
    "        self.current_df = dataframe.copy()\n",
    "        \n",
    "        print(f\"DataFrame loaded - Shape: {dataframe.shape}\")\n",
    "        print(f\"Data type: {dataframe.dtypes.iloc[0]}\")\n",
    "        print(f\"Value range: [{dataframe.min().min():.3f}, {dataframe.max().max():.3f}]\")\n",
    "        return True\n",
    "    \n",
    "    def rotate_dataframe(self, angle):\n",
    "        \"\"\"\n",
    "        Rotate DataFrame by specified angle\n",
    "        Args:\n",
    "            angle: rotation angle (90, -90, 180)\n",
    "        \"\"\"\n",
    "        if self.current_df is None:\n",
    "            print(\"No DataFrame loaded\")\n",
    "            return False\n",
    "            \n",
    "        if angle not in [90, -90, 180]:\n",
    "            print(\"Angle must be 90, -90, or 180 degrees\")\n",
    "            return False\n",
    "            \n",
    "        # Convert DataFrame to numpy array for rotation\n",
    "        data_array = self.current_df.values\n",
    "        \n",
    "        if angle == 90:\n",
    "            rotated_array = np.rot90(data_array, k=1)  # 90° counterclockwise\n",
    "        elif angle == -90:\n",
    "            rotated_array = np.rot90(data_array, k=-1)  # 90° clockwise\n",
    "        elif angle == 180:\n",
    "            rotated_array = np.rot90(data_array, k=2)  # 180°\n",
    "            \n",
    "        # Create new DataFrame with rotated data\n",
    "        self.current_df = pd.DataFrame(rotated_array)\n",
    "        self.rotation_angle = angle\n",
    "        \n",
    "        print(f\"DataFrame rotated by {angle}° - New shape: {self.current_df.shape}\")\n",
    "        return True\n",
    "    \n",
    "    def reset_rotation(self):\n",
    "        \"\"\"Reset to original DataFrame\"\"\"\n",
    "        if self.original_df is not None:\n",
    "            self.current_df = self.original_df.copy()\n",
    "            self.rotation_angle = 0\n",
    "            print(\"DataFrame reset to original orientation\")\n",
    "    \n",
    "    def slice_data(self, axis='x', start=0, end=None, step_size=1, sum_perpendicular=False):\n",
    "        \"\"\"\n",
    "        Slice DataFrame into blocks\n",
    "        Args:\n",
    "            axis: 'x' (columns) or 'y' (rows)\n",
    "            start, end: slice range\n",
    "            step_size: size of each block\n",
    "            sum_perpendicular: whether to sum along perpendicular direction\n",
    "        \"\"\"\n",
    "        if self.current_df is None:\n",
    "            print(\"No DataFrame loaded\")\n",
    "            return None\n",
    "            \n",
    "        height, width = self.current_df.shape\n",
    "        \n",
    "        if axis == 'x':\n",
    "            max_coord = width\n",
    "            if end is None: end = width\n",
    "        else:  # axis == 'y'\n",
    "            max_coord = height\n",
    "            if end is None: end = height\n",
    "                \n",
    "        # Validate coordinates\n",
    "        start = max(0, min(start, max_coord - 1))\n",
    "        end = max(start + 1, min(end, max_coord))\n",
    "        \n",
    "        # Calculate number of complete blocks\n",
    "        total_length = end - start\n",
    "        num_blocks = total_length // step_size\n",
    "        \n",
    "        print(f\"Slicing along {axis}-axis from {start} to {end}, step {step_size}\")\n",
    "        print(f\"Total blocks: {num_blocks}\")\n",
    "        \n",
    "        blocks = {}\n",
    "        \n",
    "        for i in range(num_blocks):\n",
    "            if axis == 'x':\n",
    "                block_start = start + i * step_size\n",
    "                block_end = start + (i + 1) * step_size\n",
    "                block_data = self.current_df.iloc[:, block_start:block_end]\n",
    "                \n",
    "                if sum_perpendicular:\n",
    "                    block_data = block_data.sum(axis=0).values  # Sum along rows\n",
    "            else:  # axis == 'y'\n",
    "                block_start = start + i * step_size\n",
    "                block_end = start + (i + 1) * step_size\n",
    "                block_data = self.current_df.iloc[block_start:block_end, :]\n",
    "                \n",
    "                if sum_perpendicular:\n",
    "                    block_data = block_data.sum(axis=1).values  # Sum along columns\n",
    "            \n",
    "            block_name = f\"block_{axis}_{i:03d}\"\n",
    "            blocks[block_name] = {\n",
    "                'data': block_data,\n",
    "                'axis': axis,\n",
    "                'start': block_start,\n",
    "                'end': block_end,\n",
    "                'summed': sum_perpendicular,\n",
    "                'shape': block_data.shape if hasattr(block_data, 'shape') else len(block_data)\n",
    "            }\n",
    "        \n",
    "        self.data_blocks.update(blocks)\n",
    "        print(f\"Slicing completed: {len(blocks)} blocks created\")\n",
    "        \n",
    "        return blocks\n",
    "    \n",
    "    def gaussian_func(self, x, amplitude, center, sigma, offset):\n",
    "        \"\"\"Gaussian function for fitting\"\"\"\n",
    "        return amplitude * np.exp(-((x - center) ** 2) / (2 * sigma ** 2)) + offset\n",
    "    \n",
    "    def lorentzian_func(self, x, amplitude, center, gamma, offset):\n",
    "        \"\"\"Lorentzian function for fitting\"\"\"\n",
    "        return amplitude * gamma**2 / ((x - center)**2 + gamma**2) + offset\n",
    "    \n",
    "    def find_peaks_and_analyze(self, spectrum, x_axis=None, block_name=\"spectrum\"):\n",
    "        \"\"\"\n",
    "        Comprehensive spectral peak analysis\n",
    "        Args:\n",
    "            spectrum: 1D array of spectral data\n",
    "            x_axis: x-coordinates (optional)\n",
    "            block_name: identifier for the spectrum\n",
    "        \"\"\"\n",
    "        if x_axis is None:\n",
    "            x_axis = np.arange(len(spectrum))\n",
    "        \n",
    "        # Noise filtering\n",
    "        smoothed_spectrum = gaussian_filter1d(spectrum, sigma=1.0)\n",
    "        \n",
    "        # Peak detection\n",
    "        peaks, properties = signal.find_peaks(\n",
    "            smoothed_spectrum, \n",
    "            height=np.max(smoothed_spectrum) * 0.1,  # At least 10% of max\n",
    "            distance=5,  # Minimum distance between peaks\n",
    "            prominence=np.max(smoothed_spectrum) * 0.05  # Peak prominence\n",
    "        )\n",
    "        \n",
    "        peak_analysis = {}\n",
    "        \n",
    "        for i, peak_idx in enumerate(peaks):\n",
    "            peak_x = x_axis[peak_idx]\n",
    "            peak_y = smoothed_spectrum[peak_idx]\n",
    "            \n",
    "            # Calculate FWHM and 1/e width\n",
    "            half_max = peak_y / 2\n",
    "            one_e_height = peak_y / np.e\n",
    "            \n",
    "            # Find half-maximum points\n",
    "            left_idx = peak_idx\n",
    "            right_idx = peak_idx\n",
    "            \n",
    "            # Search left for half-max\n",
    "            while left_idx > 0 and smoothed_spectrum[left_idx] > half_max:\n",
    "                left_idx -= 1\n",
    "            # Search right for half-max\n",
    "            while right_idx < len(smoothed_spectrum) - 1 and smoothed_spectrum[right_idx] > half_max:\n",
    "                right_idx += 1\n",
    "            \n",
    "            # Interpolate for precise FWHM\n",
    "            if left_idx < peak_idx:\n",
    "                left_x = np.interp(half_max, \n",
    "                                 [smoothed_spectrum[left_idx], smoothed_spectrum[left_idx + 1]],\n",
    "                                 [x_axis[left_idx], x_axis[left_idx + 1]])\n",
    "            else:\n",
    "                left_x = x_axis[left_idx]\n",
    "                \n",
    "            if right_idx > peak_idx:\n",
    "                right_x = np.interp(half_max,\n",
    "                                  [smoothed_spectrum[right_idx - 1], smoothed_spectrum[right_idx]],\n",
    "                                  [x_axis[right_idx - 1], x_axis[right_idx]])\n",
    "            else:\n",
    "                right_x = x_axis[right_idx]\n",
    "            \n",
    "            fwhm = right_x - left_x\n",
    "            \n",
    "            # Calculate 1/e width\n",
    "            left_1e_idx = peak_idx\n",
    "            right_1e_idx = peak_idx\n",
    "            \n",
    "            while left_1e_idx > 0 and smoothed_spectrum[left_1e_idx] > one_e_height:\n",
    "                left_1e_idx -= 1\n",
    "            while right_1e_idx < len(smoothed_spectrum) - 1 and smoothed_spectrum[right_1e_idx] > one_e_height:\n",
    "                right_1e_idx += 1\n",
    "                \n",
    "            # Interpolate 1/e points\n",
    "            if left_1e_idx < peak_idx:\n",
    "                left_1e_x = np.interp(one_e_height,\n",
    "                                    [smoothed_spectrum[left_1e_idx], smoothed_spectrum[left_1e_idx + 1]],\n",
    "                                    [x_axis[left_1e_idx], x_axis[left_1e_idx + 1]])\n",
    "            else:\n",
    "                left_1e_x = x_axis[left_1e_idx]\n",
    "                \n",
    "            if right_1e_idx > peak_idx:\n",
    "                right_1e_x = np.interp(one_e_height,\n",
    "                                     [smoothed_spectrum[right_1e_idx - 1], smoothed_spectrum[right_1e_idx]],\n",
    "                                     [x_axis[right_1e_idx - 1], x_axis[right_1e_idx]])\n",
    "            else:\n",
    "                right_1e_x = x_axis[right_1e_idx]\n",
    "                \n",
    "            width_1e = right_1e_x - left_1e_x\n",
    "            \n",
    "            # Curve fitting (Gaussian and Lorentzian)\n",
    "            try:\n",
    "                fit_range = max(10, int(fwhm * 2)) if fwhm > 0 else 10\n",
    "                fit_start = max(0, peak_idx - fit_range)\n",
    "                fit_end = min(len(spectrum), peak_idx + fit_range)\n",
    "                \n",
    "                x_fit = x_axis[fit_start:fit_end]\n",
    "                y_fit = smoothed_spectrum[fit_start:fit_end]\n",
    "                \n",
    "                # Gaussian fit\n",
    "                p0_gauss = [peak_y, peak_x, fwhm/2.355, np.min(y_fit)]\n",
    "                popt_gauss, _ = curve_fit(self.gaussian_func, x_fit, y_fit, p0=p0_gauss, maxfev=1000)\n",
    "                fitted_fwhm_gauss = 2.355 * abs(popt_gauss[2])\n",
    "                \n",
    "                # Lorentzian fit\n",
    "                p0_lor = [peak_y, peak_x, fwhm/2, np.min(y_fit)]\n",
    "                popt_lor, _ = curve_fit(self.lorentzian_func, x_fit, y_fit, p0=p0_lor, maxfev=1000)\n",
    "                fitted_fwhm_lor = 2 * abs(popt_lor[2])\n",
    "                \n",
    "            except:\n",
    "                popt_gauss = None\n",
    "                popt_lor = None\n",
    "                fitted_fwhm_gauss = None\n",
    "                fitted_fwhm_lor = None\n",
    "            \n",
    "            # Peak area calculation\n",
    "            peak_area = np.trapz(smoothed_spectrum[left_idx:right_idx+1], \n",
    "                               x_axis[left_idx:right_idx+1])\n",
    "            \n",
    "            # Signal-to-noise ratio\n",
    "            noise_level = np.std(smoothed_spectrum[:min(50, len(smoothed_spectrum))])\n",
    "            snr = peak_y / noise_level if noise_level > 0 else float('inf')\n",
    "            \n",
    "            peak_info = {\n",
    "                'peak_index': peak_idx,\n",
    "                'peak_position': peak_x,\n",
    "                'peak_intensity': peak_y,\n",
    "                'fwhm_measured': fwhm,\n",
    "                'width_1e': width_1e,\n",
    "                'fwhm_gaussian_fit': fitted_fwhm_gauss,\n",
    "                'fwhm_lorentzian_fit': fitted_fwhm_lor,\n",
    "                'gaussian_params': popt_gauss,\n",
    "                'lorentzian_params': popt_lor,\n",
    "                'peak_area': peak_area,\n",
    "                'snr': snr,\n",
    "                'prominence': properties['prominences'][i] if i < len(properties['prominences']) else None\n",
    "            }\n",
    "            \n",
    "            peak_analysis[f'peak_{i+1}'] = peak_info\n",
    "        \n",
    "        # Store analysis results\n",
    "        analysis_result = {\n",
    "            'original_spectrum': spectrum,\n",
    "            'smoothed_spectrum': smoothed_spectrum,\n",
    "            'x_axis': x_axis,\n",
    "            'peaks': peak_analysis,\n",
    "            'num_peaks': len(peaks)\n",
    "        }\n",
    "        \n",
    "        self.processed_spectra[block_name] = analysis_result\n",
    "        return analysis_result\n",
    "    \n",
    "    def visualize_spectrum_analysis(self, block_name):\n",
    "        \"\"\"Visualize spectral analysis results\"\"\"\n",
    "        if block_name not in self.processed_spectra:\n",
    "            print(f\"No analysis results found for {block_name}\")\n",
    "            return\n",
    "            \n",
    "        result = self.processed_spectra[block_name]\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "        \n",
    "        # Top plot: original and smoothed spectra\n",
    "        ax1.plot(result['x_axis'], result['original_spectrum'], 'lightblue', alpha=0.7, label='Original')\n",
    "        ax1.plot(result['x_axis'], result['smoothed_spectrum'], 'blue', linewidth=2, label='Smoothed')\n",
    "        \n",
    "        # Mark peaks\n",
    "        for peak_name, peak_info in result['peaks'].items():\n",
    "            ax1.plot(peak_info['peak_position'], peak_info['peak_intensity'], 'ro', markersize=8)\n",
    "            ax1.annotate(f\"{peak_name}\\nPos: {peak_info['peak_position']:.2f}\", \n",
    "                        (peak_info['peak_position'], peak_info['peak_intensity']),\n",
    "                        xytext=(10, 10), textcoords='offset points', fontsize=8)\n",
    "        \n",
    "        ax1.set_title(f'Spectral Analysis - {block_name}')\n",
    "        ax1.set_xlabel('Position/Wavelength')\n",
    "        ax1.set_ylabel('Intensity')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Bottom plot: peak width comparison\n",
    "        if result['peaks']:\n",
    "            peak_names = list(result['peaks'].keys())\n",
    "            fwhms = [result['peaks'][name]['fwhm_measured'] for name in peak_names]\n",
    "            width_1es = [result['peaks'][name]['width_1e'] for name in peak_names]\n",
    "            \n",
    "            x_pos = np.arange(len(peak_names))\n",
    "            width = 0.35\n",
    "            \n",
    "            ax2.bar(x_pos - width/2, fwhms, width, label='FWHM', alpha=0.8)\n",
    "            ax2.bar(x_pos + width/2, width_1es, width, label='1/e Width', alpha=0.8)\n",
    "            \n",
    "            ax2.set_xlabel('Peaks')\n",
    "            ax2.set_ylabel('Width')\n",
    "            ax2.set_title('Peak Width Comparison')\n",
    "            ax2.set_xticks(x_pos)\n",
    "            ax2.set_xticklabels(peak_names, rotation=45)\n",
    "            ax2.legend()\n",
    "            ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print detailed results\n",
    "        print(f\"\\n=== {block_name} Analysis Results ===\")\n",
    "        for peak_name, peak_info in result['peaks'].items():\n",
    "            print(f\"\\n{peak_name}:\")\n",
    "            print(f\"  Position: {peak_info['peak_position']:.3f}\")\n",
    "            print(f\"  Intensity: {peak_info['peak_intensity']:.3f}\")\n",
    "            print(f\"  FWHM (measured): {peak_info['fwhm_measured']:.3f}\")\n",
    "            print(f\"  1/e width: {peak_info['width_1e']:.3f}\")\n",
    "            if peak_info['fwhm_gaussian_fit']:\n",
    "                print(f\"  FWHM (Gaussian fit): {peak_info['fwhm_gaussian_fit']:.3f}\")\n",
    "            if peak_info['fwhm_lorentzian_fit']:\n",
    "                print(f\"  FWHM (Lorentzian fit): {peak_info['fwhm_lorentzian_fit']:.3f}\")\n",
    "            print(f\"  SNR: {peak_info['snr']:.2f}\")\n",
    "    \n",
    "    def visualize_dataframe(self):\n",
    "        \"\"\"Visualize current DataFrame\"\"\"\n",
    "        if self.current_df is None:\n",
    "            print(\"No DataFrame loaded\")\n",
    "            return\n",
    "            \n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        img = ax.imshow(self.current_df.values, cmap='gray', aspect='auto')\n",
    "        plt.colorbar(img, ax=ax, label='Intensity')\n",
    "        \n",
    "        title = f'DataFrame Visualization'\n",
    "        if self.rotation_angle != 0:\n",
    "            title += f' (Rotated {self.rotation_angle}°)'\n",
    "        \n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel('Columns')\n",
    "        ax.set_ylabel('Rows')\n",
    "        plt.show()\n",
    "    \n",
    "    def save_analysis_results(self, filename=\"spectral_analysis_results.pkl\"):\n",
    "        \"\"\"Save analysis results to file\"\"\"\n",
    "        save_data = {\n",
    "            'data_blocks': self.data_blocks,\n",
    "            'processed_spectra': self.processed_spectra,\n",
    "            'rotation_angle': self.rotation_angle,\n",
    "            'dataframe_shape': self.current_df.shape if self.current_df is not None else None\n",
    "        }\n",
    "        \n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(save_data, f)\n",
    "        \n",
    "        print(f\"Analysis results saved to: {filename}\")\n",
    "    \n",
    "    def load_analysis_results(self, filename):\n",
    "        \"\"\"Load previously saved analysis results\"\"\"\n",
    "        try:\n",
    "            with open(filename, 'rb') as f:\n",
    "                save_data = pickle.load(f)\n",
    "            \n",
    "            self.data_blocks = save_data.get('data_blocks', {})\n",
    "            self.processed_spectra = save_data.get('processed_spectra', {})\n",
    "            self.rotation_angle = save_data.get('rotation_angle', 0)\n",
    "            \n",
    "            print(f\"Analysis results loaded from: {filename}\")\n",
    "            print(f\"Loaded {len(self.data_blocks)} data blocks and {len(self.processed_spectra)} spectral analyses\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading file: {e}\")\n",
    "    \n",
    "    def list_data_blocks(self):\n",
    "        \"\"\"List all available data blocks\"\"\"\n",
    "        if not self.data_blocks:\n",
    "            print(\"No data blocks available\")\n",
    "            return\n",
    "            \n",
    "        print(\"Available data blocks:\")\n",
    "        for name, block in self.data_blocks.items():\n",
    "            print(f\"  - {name}: shape {block['shape']}, axis {block['axis']}, \"\n",
    "                  f\"range [{block['start']}:{block['end']}], summed: {block['summed']}\")\n",
    "    \n",
    "    def list_processed_spectra(self):\n",
    "        \"\"\"List all processed spectral analyses\"\"\"\n",
    "        if not self.processed_spectra:\n",
    "            print(\"No processed spectra available\")\n",
    "            return\n",
    "            \n",
    "        print(\"Available spectral analyses:\")\n",
    "        for name, result in self.processed_spectra.items():\n",
    "            print(f\"  - {name}: {result['num_peaks']} peaks detected\")\n",
    "\n",
    "# Main program\n",
    "if __name__ == \"__main__\":\n",
    "    processor = DataFrameSpectralProcessor()\n",
    "    # Note: Load your DataFrame here with processor.load_dataframe(your_df)\n",
    "    print(\"DataFrame Spectral Processor initialized\")\n",
    "    print(\"Use processor.load_dataframe(your_df) to start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16994acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "class DataFrameSpectralProcessor:\n",
    "    def __init__(self, dataframe=None):\n",
    "        \"\"\"\n",
    "        使用可选的 2D DataFrame 初始化处理器\n",
    "        参数:\n",
    "            dataframe: 表示光谱/图像数据的 2D pandas DataFrame\n",
    "        \"\"\"\n",
    "        self.original_df = dataframe\n",
    "        self.current_df = None\n",
    "        self.data_blocks = {}\n",
    "        self.processed_spectra = {}\n",
    "        self.rotation_angle = 0\n",
    "        \n",
    "    def load_dataframe(self, dataframe):\n",
    "        \"\"\"加载 2D DataFrame\"\"\"\n",
    "        if not isinstance(dataframe, pd.DataFrame):\n",
    "            raise ValueError(\"输入必须是 pandas DataFrame 类型\")\n",
    "        \n",
    "        self.original_df = dataframe.copy()\n",
    "        self.current_df = dataframe.copy()\n",
    "        \n",
    "        print(f\"DataFrame 已加载 - 形状: {dataframe.shape}\")\n",
    "        print(f\"数据类型: {dataframe.dtypes.iloc[0]}\")\n",
    "        print(f\"数值范围: [{dataframe.min().min():.3f}, {dataframe.max().max():.3f}]\")\n",
    "        return True\n",
    "    \n",
    "    def rotate_dataframe(self, angle):\n",
    "        \"\"\"\n",
    "        将 DataFrame 旋转指定角度\n",
    "        参数:\n",
    "            angle: 旋转角度（90、-90 或 180）\n",
    "        \"\"\"\n",
    "        if self.current_df is None:\n",
    "            print(\"尚未加载 DataFrame\")\n",
    "            return False\n",
    "            \n",
    "        if angle not in [90, -90, 180]:\n",
    "            print(\"角度必须是 90、-90 或 180 度\")\n",
    "            return False\n",
    "            \n",
    "        # 将 DataFrame 转换为 numpy 数组以进行旋转\n",
    "        data_array = self.current_df.values\n",
    "        \n",
    "        if angle == 90:\n",
    "            rotated_array = np.rot90(data_array, k=1)  # 逆时针旋转 90°\n",
    "        elif angle == -90:\n",
    "            rotated_array = np.rot90(data_array, k=-1)  # 顺时针旋转 90°\n",
    "        elif angle == 180:\n",
    "            rotated_array = np.rot90(data_array, k=2)  # 旋转 180°\n",
    "            \n",
    "        # 用旋转后的数据创建新的 DataFrame\n",
    "        self.current_df = pd.DataFrame(rotated_array)\n",
    "        self.rotation_angle = angle\n",
    "        \n",
    "        print(f\"DataFrame 已旋转 {angle}° - 新形状: {self.current_df.shape}\")\n",
    "        return True\n",
    "    \n",
    "    def reset_rotation(self):\n",
    "        \"\"\"重置为原始 DataFrame\"\"\"\n",
    "        if self.original_df is not None:\n",
    "            self.current_df = self.original_df.copy()\n",
    "            self.rotation_angle = 0\n",
    "            print(\"DataFrame 已重置为原始方向\")\n",
    "    \n",
    "    def slice_data(self, axis='x', start=0, end=None, step_size=1, sum_perpendicular=False):\n",
    "        \"\"\"\n",
    "        将 DataFrame 按块切片\n",
    "        参数:\n",
    "            axis: 'x'（按列切）或 'y'（按行切）\n",
    "            start, end: 切片范围\n",
    "            step_size: 每个块的大小\n",
    "            sum_perpendicular: 是否沿垂直方向求和\n",
    "        \"\"\"\n",
    "        if self.current_df is None:\n",
    "            print(\"尚未加载 DataFrame\")\n",
    "            return None\n",
    "            \n",
    "        height, width = self.current_df.shape\n",
    "        \n",
    "        if axis == 'x':\n",
    "            max_coord = width\n",
    "            if end is None: end = width\n",
    "        else:  # axis == 'y'\n",
    "            max_coord = height\n",
    "            if end is None: end = height\n",
    "                \n",
    "        # 校验坐标\n",
    "        start = max(0, min(start, max_coord - 1))\n",
    "        end = max(start + 1, min(end, max_coord))\n",
    "        \n",
    "        # 计算完整块的数量\n",
    "        total_length = end - start\n",
    "        num_blocks = total_length // step_size\n",
    "        \n",
    "        print(f\"沿 {axis}-轴切片，从 {start} 到 {end}，步长为 {step_size}\")\n",
    "        print(f\"总块数: {num_blocks}\")\n",
    "        \n",
    "        blocks = {}\n",
    "        \n",
    "        for i in range(num_blocks):\n",
    "            if axis == 'x':\n",
    "                block_start = start + i * step_size\n",
    "                block_end = start + (i + 1) * step_size\n",
    "                block_data = self.current_df.iloc[:, block_start:block_end]\n",
    "                \n",
    "                if sum_perpendicular:\n",
    "                    block_data = block_data.sum(axis=0).values  # 沿行方向求和\n",
    "            else:  # axis == 'y'\n",
    "                block_start = start + i * step_size\n",
    "                block_end = start + (i + 1) * step_size\n",
    "                block_data = self.current_df.iloc[block_start:block_end, :]\n",
    "                \n",
    "                if sum_perpendicular:\n",
    "                    block_data = block_data.sum(axis=1).values  # 沿列方向求和\n",
    "            \n",
    "            block_name = f\"block_{axis}_{i:03d}\"\n",
    "            blocks[block_name] = {\n",
    "                'data': block_data,\n",
    "                'axis': axis,\n",
    "                'start': block_start,\n",
    "                'end': block_end,\n",
    "                'summed': sum_perpendicular,\n",
    "                'shape': block_data.shape if hasattr(block_data, 'shape') else len(block_data)\n",
    "            }\n",
    "        \n",
    "        self.data_blocks.update(blocks)\n",
    "        print(f\"切片完成：共创建 {len(blocks)} 个数据块\")\n",
    "        \n",
    "        return blocks\n",
    "    \n",
    "    def gaussian_func(self, x, amplitude, center, sigma, offset):\n",
    "        \"\"\"用于拟合的高斯函数\"\"\"\n",
    "        return amplitude * np.exp(-((x - center) ** 2) / (2 * sigma ** 2)) + offset\n",
    "    \n",
    "    def lorentzian_func(self, x, amplitude, center, gamma, offset):\n",
    "        \"\"\"用于拟合的洛伦兹函数\"\"\"\n",
    "        return amplitude * gamma**2 / ((x - center)**2 + gamma**2) + offset\n",
    "    \n",
    "    def find_peaks_and_analyze(self, spectrum, x_axis=None, block_name=\"spectrum\"):\n",
    "        \"\"\"\n",
    "        全面的光谱峰分析\n",
    "        参数:\n",
    "            spectrum: 一维光谱数据\n",
    "            x_axis: x 坐标（可选）\n",
    "            block_name: 光谱标识符\n",
    "        \"\"\"\n",
    "        if x_axis is None:\n",
    "            x_axis = np.arange(len(spectrum))\n",
    "        \n",
    "        # 噪声滤波\n",
    "        smoothed_spectrum = gaussian_filter1d(spectrum, sigma=1.0)\n",
    "        \n",
    "        # 峰值检测\n",
    "        peaks, properties = signal.find_peaks(\n",
    "            smoothed_spectrum, \n",
    "            height=np.max(smoothed_spectrum) * 0.1,  # 至少为最大值的10%\n",
    "            distance=5,  # 峰值之间的最小距离\n",
    "            prominence=np.max(smoothed_spectrum) * 0.05  # 峰值显著性\n",
    "        )\n",
    "        \n",
    "        peak_analysis = {}\n",
    "        \n",
    "        for i, peak_idx in enumerate(peaks):\n",
    "            peak_x = x_axis[peak_idx]\n",
    "            peak_y = smoothed_spectrum[peak_idx]\n",
    "            \n",
    "            # 计算 FWHM 和 1/e 宽度\n",
    "            half_max = peak_y / 2\n",
    "            one_e_height = peak_y / np.e\n",
    "            \n",
    "            # 查找半高宽点\n",
    "            left_idx = peak_idx\n",
    "            right_idx = peak_idx\n",
    "            \n",
    "            # 向左查找半高点\n",
    "            while left_idx > 0 and smoothed_spectrum[left_idx] > half_max:\n",
    "                left_idx -= 1\n",
    "            # 向右查找半高点\n",
    "            while right_idx < len(smoothed_spectrum) - 1 and smoothed_spectrum[right_idx] > half_max:\n",
    "                right_idx += 1\n",
    "            \n",
    "            # 插值计算 FWHM 边界\n",
    "            if left_idx < peak_idx:\n",
    "                left_x = np.interp(half_max, \n",
    "                                 [smoothed_spectrum[left_idx], smoothed_spectrum[left_idx + 1]],\n",
    "                                 [x_axis[left_idx], x_axis[left_idx + 1]])\n",
    "            else:\n",
    "                left_x = x_axis[left_idx]\n",
    "                \n",
    "            if right_idx > peak_idx:\n",
    "                right_x = np.interp(half_max,\n",
    "                                  [smoothed_spectrum[right_idx - 1], smoothed_spectrum[right_idx]],\n",
    "                                  [x_axis[right_idx - 1], x_axis[right_idx]])\n",
    "            else:\n",
    "                right_x = x_axis[right_idx]\n",
    "            \n",
    "            fwhm = right_x - left_x\n",
    "            \n",
    "            # 计算 1/e 宽度\n",
    "            left_1e_idx = peak_idx\n",
    "            right_1e_idx = peak_idx\n",
    "            \n",
    "            while left_1e_idx > 0 and smoothed_spectrum[left_1e_idx] > one_e_height:\n",
    "                left_1e_idx -= 1\n",
    "            while right_1e_idx < len(smoothed_spectrum) - 1 and smoothed_spectrum[right_1e_idx] > one_e_height:\n",
    "                right_1e_idx += 1\n",
    "                \n",
    "            # 插值计算 1/e 边界\n",
    "            if left_1e_idx < peak_idx:\n",
    "                left_1e_x = np.interp(one_e_height,\n",
    "                                    [smoothed_spectrum[left_1e_idx], smoothed_spectrum[left_1e_idx + 1]],\n",
    "                                    [x_axis[left_1e_idx], x_axis[left_1e_idx + 1]])\n",
    "            else:\n",
    "                left_1e_x = x_axis[left_1e_idx]\n",
    "                \n",
    "            if right_1e_idx > peak_idx:\n",
    "                right_1e_x = np.interp(one_e_height,\n",
    "                                     [smoothed_spectrum[right_1e_idx - 1], smoothed_spectrum[right_1e_idx]],\n",
    "                                     [x_axis[right_1e_idx - 1], x_axis[right_1e_idx]])\n",
    "            else:\n",
    "                right_1e_x = x_axis[right_1e_idx]\n",
    "                \n",
    "            width_1e = right_1e_x - left_1e_x\n",
    "            \n",
    "            # 曲线拟合（高斯和洛伦兹）\n",
    "            try:\n",
    "                fit_range = max(10, int(fwhm * 2)) if fwhm > 0 else 10\n",
    "                fit_start = max(0, peak_idx - fit_range)\n",
    "                fit_end = min(len(spectrum), peak_idx + fit_range)\n",
    "                \n",
    "                x_fit = x_axis[fit_start:fit_end]\n",
    "                y_fit = smoothed_spectrum[fit_start:fit_end]\n",
    "                \n",
    "                # 高斯拟合\n",
    "                p0_gauss = [peak_y, peak_x, fwhm/2.355, np.min(y_fit)]\n",
    "                popt_gauss, _ = curve_fit(self.gaussian_func, x_fit, y_fit, p0=p0_gauss, maxfev=1000)\n",
    "                fitted_fwhm_gauss = 2.355 * abs(popt_gauss[2])\n",
    "                \n",
    "                # 洛伦兹拟合\n",
    "                p0_lor = [peak_y, peak_x, fwhm/2, np.min(y_fit)]\n",
    "                popt_lor, _ = curve_fit(self.lorentzian_func, x_fit, y_fit, p0=p0_lor, maxfev=1000)\n",
    "                fitted_fwhm_lor = 2 * abs(popt_lor[2])\n",
    "                \n",
    "            except:\n",
    "                popt_gauss = None\n",
    "                popt_lor = None\n",
    "                fitted_fwhm_gauss = None\n",
    "                fitted_fwhm_lor = None\n",
    "            \n",
    "            # 计算峰面积\n",
    "            peak_area = np.trapz(smoothed_spectrum[left_idx:right_idx+1], \n",
    "                               x_axis[left_idx:right_idx+1])\n",
    "            \n",
    "            # 信噪比\n",
    "            noise_level = np.std(smoothed_spectrum[:min(50, len(smoothed_spectrum))])\n",
    "            snr = peak_y / noise_level if noise_level > 0 else float('inf')\n",
    "            \n",
    "            peak_info = {\n",
    "                'peak_index': peak_idx,\n",
    "                'peak_position': peak_x,\n",
    "                'peak_intensity': peak_y,\n",
    "                'fwhm_measured': fwhm,\n",
    "                'width_1e': width_1e,\n",
    "                'fwhm_gaussian_fit': fitted_fwhm_gauss,\n",
    "                'fwhm_lorentzian_fit': fitted_fwhm_lor,\n",
    "                'gaussian_params': popt_gauss,\n",
    "                'lorentzian_params': popt_lor,\n",
    "                'peak_area': peak_area,\n",
    "                'snr': snr,\n",
    "                'prominence': properties['prominences'][i] if i < len(properties['prominences']) else None\n",
    "            }\n",
    "            \n",
    "            peak_analysis[f'peak_{i+1}'] = peak_info\n",
    "        \n",
    "        # 存储分析结果\n",
    "        analysis_result = {\n",
    "            'original_spectrum': spectrum,\n",
    "            'smoothed_spectrum': smoothed_spectrum,\n",
    "            'x_axis': x_axis,\n",
    "            'peaks': peak_analysis,\n",
    "            'num_peaks': len(peaks)\n",
    "        }\n",
    "        \n",
    "        self.processed_spectra[block_name] = analysis_result\n",
    "        return analysis_result\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
